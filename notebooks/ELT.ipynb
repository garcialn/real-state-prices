{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320366f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb as duck\n",
    "import pyarrow as pa\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "con = duck.connect(database='/home/garcia-ln/Documentos/real-state-prices/data/processed/real_state.duckdb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db7da078",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## JSON > Parquet\n",
    "Before starting the process of cleaning and transforming the data for  our analysis, we're gonna make sure to convert the files into `.parquet` format so that we're always dealing with optimazed performance datasets, no matter the situation.  \n",
    "\n",
    "For that, we're gonna start by loading our data into [Pola.rs](pola.rs 'Most Efficient DataFrame Lib for Python') dataframes and try to get some information from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c20129",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sp_dt = pl.read_json('/home/garcia-ln/Documentos/real-state-prices/data/raw/sp_properties.json')\n",
    "rj_dt = pl.read_json('/home/garcia-ln/Documentos/real-state-prices/data/raw/rj_properties.json')\n",
    "pa_dt = pl.read_json('/home/garcia-ln/Documentos/real-state-prices/data/raw/pa_properties.json')\n",
    "bh_dt = pl.read_json('/home/garcia-ln/Documentos/real-state-prices/data/raw/bh_properties.json')\n",
    "\n",
    "#sp_dt.write_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/sp_properties.parquet')\n",
    "#rj_dt.write_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/rj_properties.parquet')\n",
    "#pa_dt.write_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/pa_properties.parquet')\n",
    "#bh_dt.write_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/bh_properties.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e56de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sql_sp = '''\n",
    "    CREATE TABLE sp_tbl as \n",
    "        SELECT * FROM '~/Documentos/real-state-prices/data/processed/sp_properties.parquet';\n",
    "    ALTER TABLE sp_tbl\n",
    "        ADD COLUMN city VARCHAR DEFAULT 'Sao_Paulo'\n",
    "'''\n",
    "\n",
    "sql_rj = '''\n",
    "    CREATE TABLE rj_tbl as \n",
    "         SELECT * FROM '~/Documentos/real-state-prices/data/processed/rj_properties.parquet';\n",
    "    ALTER TABLE rj_tbl\n",
    "        ADD COLUMN city VARCHAR DEFAULT 'Rio_de_Janeiro'\n",
    "'''\n",
    "\n",
    "sql_pa = '''\n",
    "    CREATE TABLE pa_tbl as \n",
    "        SELECT * FROM '~/Documentos/real-state-prices/data/processed/pa_properties.parquet';\n",
    "    ALTER TABLE pa_tbl\n",
    "        ADD COLUMN city VARCHAR DEFAULT 'Porto_Alegre'\n",
    "'''\n",
    "\n",
    "sql_bh = '''\n",
    "    CREATE TABLE bh_tbl as \n",
    "        SELECT * FROM '~/Documentos/real-state-prices/data/processed/bh_properties.parquet';\n",
    "    ALTER TABLE bh_tbl\n",
    "        ADD COLUMN city VARCHAR DEFAULT 'Belo_Horizonte'\n",
    "'''\n",
    "\n",
    "con.execute(sql_sp).fetchall()\n",
    "sp_df = con.table('sp_tbl').df()\n",
    "display(sp_df)\n",
    "\n",
    "\n",
    "con.execute(sql_rj).fetchall()\n",
    "rj_df = con.table('rj_tbl').df()\n",
    "display(rj_df)\n",
    "\n",
    "\n",
    "con.execute(sql_pa).fetchall()\n",
    "pa_df = con.table('pa_tbl').df()\n",
    "display(pa_df)\n",
    "\n",
    "\n",
    "con.execute(sql_bh).fetchall()\n",
    "bh_df = con.table('bh_tbl').df()\n",
    "display(bh_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a0d0512",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dtypes\n",
    "\n",
    "Now that we altered the file from `.json` to `.parque` and added the feature to our dataset we're gonna **add all the tables together and define the dtypes of our data**.  \n",
    "\n",
    "\n",
    "After that we're gonna make sure to **change all dtypes of our dataset**, to keep a tidy dataset for our cleaning, analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b59411",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "    CREATE TABLE properties as\n",
    "        SELECT * FROM sp_tbl \n",
    "    UNION ALL \n",
    "        SELECT * FROM rj_tbl \n",
    "    UNION ALL \n",
    "        SELECT * FROM pa_tbl \n",
    "    UNION ALL \n",
    "        SELECT * FROM bh_tbl\n",
    "'''\n",
    "\n",
    "#con.execute(sql).fetchall()\n",
    "\n",
    "properties = pl.from_pandas(con.table('properties').df())\n",
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49645736",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# The code for change dtypes on Polars\n",
    "properties = properties.with_columns(\n",
    "    [\n",
    "        (pl.col('type').cast(pl.Categorical)),\n",
    "        (pl.col('city').cast(pl.Categorical)),\n",
    "        (pl.col('address').cast(pl.Categorical)),\n",
    "        (pl.col('neighborhood').cast(pl.Categorical)),\n",
    "        (pl.col('footage').cast(pl.Int16)),\n",
    "        (pl.col('doorms').cast(pl.Int8)),\n",
    "        (pl.col('garages').cast(pl.Int8)),\n",
    "        (pl.col('price').cast(pl.Int32))\n",
    "    ]\n",
    ")\n",
    "\n",
    "#properties.write_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/properties.parquet')\n",
    "properties = pl.read_parquet('/home/garcia-ln/Documentos/real-state-prices/data/processed/properties.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073b744",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## here's the SQL query for changing the dtypes of the properties table\n",
    "\n",
    "con.execute('''\n",
    "    ALTER TABLE properties\n",
    "        ALTER type SET DATA TYPE VARCHAR;\n",
    "    ALTER TABLE properties\n",
    "        ALTER city SET DATA TYPE VARCHAR;\n",
    "    ALTER TABLE properties\n",
    "        ALTER address SET DATA TYPE VARCHAR;\n",
    "    ALTER TABLE properties\n",
    "        ALTER neighborhood SET DATA TYPE VARCHAR;\n",
    "    ALTER TABLE properties    \n",
    "        ALTER footage SET DATA TYPE SMALLINT;\n",
    "    ALTER TABLE properties    \n",
    "        ALTER doorms SET DATA TYPE INT2;\n",
    "    ALTER TABLE properties\n",
    "        ALTER garages SET DATA TYPE INT2;\n",
    "    ALTER TABLE properties    \n",
    "        ALTER price SET DATA TYPE INT4\n",
    "'''\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b30c192b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EDA\n",
    "lets go for the EDA step of our project. Here we're gonna go through our dataset before start applying the changes for **data cleaning, feature selection and engineering and decoding our categorical features.**  \n",
    "\n",
    "We're gonna start by understanding the basic information on the qualy and quant features, followed by some visualizations to help on the insights for our analysis.  \n",
    "\n",
    "Before we go on, lets make some changes on our dataset to make sure we'll be able to work on it. In this case, i'm gonna use `seaborn` for our dataviz (wich requires the DF on `pandas` format, and not `polars`) insted of using `plotly express` (wich we can use the `polars` DF and generates interactive plots). The reason for that, is for prettier dataviz made simple and easy, seaborn is the way to go and given that we don't have such a big df, there's no problem transforming the pl.df to pd.df just for plotting.  \n",
    "\n",
    "Said that, we're gonna by transforming the properties df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f422c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(properties.null_count())\n",
    "null = properties.filter(pl.col('type')==None).to_pandas()\n",
    "df = properties.to_pandas()\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae6002f",
   "metadata": {},
   "source": [
    "From this, we can observe that we have a very small volume of missing values. But before we do anything with it, lets check if we have those null values concentrated on a group, or if it's well distributed through all citys and prices. After that, we decide whether to **drop those null values, or make some statistical interpolation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d960d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context='notebook', \n",
    "    style='darkgrid', \n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "sns.countplot(data=null, \n",
    "    x='city',\n",
    "    hue='city', \n",
    "    saturation=2, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    context='notebook', \n",
    "    style='darkgrid', \n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "sns.displot(\n",
    "    data=df, \n",
    "    x='price', \n",
    "    hue='city',\n",
    "    fill=True, \n",
    "    common_norm=False, \n",
    "    col='type',\n",
    "    alpha=.2,\n",
    "    kind='kde',\n",
    "    height=4, \n",
    "    aspect=1.4,\n",
    "    log_scale=True,\n",
    "    linewidth=2.5,\n",
    "    col_wrap=3\n",
    ").set_axis_labels('Prices', 'Density').set_titles('{col_name}')#.set(xticks='plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37d3f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910294b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457298b-ddc4-4f35-8ebd-4299ee7078af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "properties.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2784a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "properties['type'].value_counts().unique()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d51eaf2bab5ade07ebe00b6ad723ed46cec5b86ecd5c27970a62f590a707991f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
